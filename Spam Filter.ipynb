{
 "metadata": {
  "name": "",
  "signature": "sha256:dc192cbb57e021eb5bee96d86ae42a8b7df706b3edb71acc6d4f05e1e27df0e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat spambase.DOCUMENTATION"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1. Title:  SPAM E-mail Database\r",
        "\r\n",
        "\r",
        "\r\n",
        "2. Sources:\r",
        "\r\n",
        "   (a) Creators: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\r",
        "\r\n",
        "        Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\r",
        "\r\n",
        "   (b) Donor: George Forman (gforman at nospam hpl.hp.com)  650-857-7835\r",
        "\r\n",
        "   (c) Generated: June-July 1999\r",
        "\r\n",
        "\r",
        "\r\n",
        "3. Past Usage:\r",
        "\r\n",
        "   (a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\r",
        "\r\n",
        "   (b) Determine whether a given email is spam or not.\r",
        "\r\n",
        "   (c) ~7% misclassification error.\r",
        "\r\n",
        "       False positives (marking good mail as spam) are very undesirable.\r",
        "\r\n",
        "       If we insist on zero false positives in the training/testing set,\r",
        "\r\n",
        "       20-25% of the spam passed through the filter.\r",
        "\r\n",
        "\r",
        "\r\n",
        "4. Relevant Information:\r",
        "\r\n",
        "        The \"spam\" concept is diverse: advertisements for products/web\r",
        "\r\n",
        "        sites, make money fast schemes, chain letters, pornography...\r",
        "\r\n",
        "\tOur collection of spam e-mails came from our postmaster and \r",
        "\r\n",
        "\tindividuals who had filed spam.  Our collection of non-spam \r",
        "\r\n",
        "\te-mails came from filed work and personal e-mails, and hence\r",
        "\r\n",
        "\tthe word 'george' and the area code '650' are indicators of \r",
        "\r\n",
        "\tnon-spam.  These are useful when constructing a personalized \r",
        "\r\n",
        "\tspam filter.  One would either have to blind such non-spam \r",
        "\r\n",
        "\tindicators or get a very wide collection of non-spam to \r",
        "\r\n",
        "\tgenerate a general purpose spam filter.\r",
        "\r\n",
        "\r",
        "\r\n",
        "        For background on spam:\r",
        "\r\n",
        "        Cranor, Lorrie F., LaMacchia, Brian A.  Spam! \r",
        "\r\n",
        "        Communications of the ACM, 41(8):74-83, 1998.\r",
        "\r\n",
        "\r",
        "\r\n",
        "5. Number of Instances: 4601 (1813 Spam = 39.4%)\r",
        "\r\n",
        "\r",
        "\r\n",
        "6. Number of Attributes: 58 (57 continuous, 1 nominal class label)\r",
        "\r\n",
        "\r",
        "\r\n",
        "7. Attribute Information:\r",
        "\r\n",
        "The last column of 'spambase.data' denotes whether the e-mail was \r",
        "\r\n",
        "considered spam (1) or not (0), i.e. unsolicited commercial e-mail.  \r",
        "\r\n",
        "Most of the attributes indicate whether a particular word or\r",
        "\r\n",
        "character was frequently occuring in the e-mail.  The run-length\r",
        "\r\n",
        "attributes (55-57) measure the length of sequences of consecutive \r",
        "\r\n",
        "capital letters.  For the statistical measures of each attribute, \r",
        "\r\n",
        "see the end of this file.  Here are the definitions of the attributes:\r",
        "\r\n",
        "\r",
        "\r\n",
        "48 continuous real [0,100] attributes of type word_freq_WORD \r",
        "\r\n",
        "= percentage of words in the e-mail that match WORD,\r",
        "\r\n",
        "i.e. 100 * (number of times the WORD appears in the e-mail) / \r",
        "\r\n",
        "total number of words in e-mail.  A \"word\" in this case is any \r",
        "\r\n",
        "string of alphanumeric characters bounded by non-alphanumeric \r",
        "\r\n",
        "characters or end-of-string.\r",
        "\r\n",
        "\r",
        "\r\n",
        "6 continuous real [0,100] attributes of type char_freq_CHAR\r",
        "\r\n",
        "= percentage of characters in the e-mail that match CHAR,\r",
        "\r\n",
        "i.e. 100 * (number of CHAR occurences) / total characters in e-mail\r",
        "\r\n",
        "\r",
        "\r\n",
        "1 continuous real [1,...] attribute of type capital_run_length_average\r",
        "\r\n",
        "= average length of uninterrupted sequences of capital letters\r",
        "\r\n",
        "\r",
        "\r\n",
        "1 continuous integer [1,...] attribute of type capital_run_length_longest\r",
        "\r\n",
        "= length of longest uninterrupted sequence of capital letters\r",
        "\r\n",
        "\r",
        "\r\n",
        "1 continuous integer [1,...] attribute of type capital_run_length_total\r",
        "\r\n",
        "= sum of length of uninterrupted sequences of capital letters\r",
        "\r\n",
        "= total number of capital letters in the e-mail\r",
        "\r\n",
        "\r",
        "\r\n",
        "1 nominal {0,1} class attribute of type spam\r",
        "\r\n",
        "= denotes whether the e-mail was considered spam (1) or not (0), \r",
        "\r\n",
        "i.e. unsolicited commercial e-mail.  \r",
        "\r\n",
        "\r",
        "\r\n",
        "\r",
        "\r\n",
        "8. Missing Attribute Values: None\r",
        "\r\n",
        "\r",
        "\r\n",
        "9. Class Distribution:\r",
        "\r\n",
        "\tSpam\t  1813  (39.4%)\r",
        "\r\n",
        "\tNon-Spam  2788  (60.6%)\r",
        "\r\n",
        "\r",
        "\r\n",
        "\r",
        "\r\n",
        "Attribute Statistics:\r",
        "\r\n",
        "   Min: Max:   Average:  Std.Dev: Coeff.Var_%: \r",
        "\r\n",
        "1  0    4.54   0.10455   0.30536  292          \r",
        "\r\n",
        "2  0    14.28  0.21301   1.2906   606          \r",
        "\r\n",
        "3  0    5.1    0.28066   0.50414  180          \r",
        "\r\n",
        "4  0    42.81  0.065425  1.3952   2130         \r",
        "\r\n",
        "5  0    10     0.31222   0.67251  215          \r",
        "\r\n",
        "6  0    5.88   0.095901  0.27382  286          \r",
        "\r\n",
        "7  0    7.27   0.11421   0.39144  343          \r",
        "\r\n",
        "8  0    11.11  0.10529   0.40107  381          \r",
        "\r\n",
        "9  0    5.26   0.090067  0.27862  309          \r",
        "\r\n",
        "10 0    18.18  0.23941   0.64476  269          \r",
        "\r\n",
        "11 0    2.61   0.059824  0.20154  337          \r",
        "\r\n",
        "12 0    9.67   0.5417    0.8617   159          \r",
        "\r\n",
        "13 0    5.55   0.09393   0.30104  320          \r",
        "\r\n",
        "14 0    10     0.058626  0.33518  572          \r",
        "\r\n",
        "15 0    4.41   0.049205  0.25884  526          \r",
        "\r\n",
        "16 0    20     0.24885   0.82579  332          \r",
        "\r\n",
        "17 0    7.14   0.14259   0.44406  311          \r",
        "\r\n",
        "18 0    9.09   0.18474   0.53112  287          \r",
        "\r\n",
        "19 0    18.75  1.6621    1.7755   107          \r",
        "\r\n",
        "20 0    18.18  0.085577  0.50977  596          \r",
        "\r\n",
        "21 0    11.11  0.80976   1.2008   148          \r",
        "\r\n",
        "22 0    17.1   0.1212    1.0258   846          \r",
        "\r\n",
        "23 0    5.45   0.10165   0.35029  345          \r",
        "\r\n",
        "24 0    12.5   0.094269  0.44264  470          \r",
        "\r\n",
        "25 0    20.83  0.5495    1.6713   304          \r",
        "\r\n",
        "26 0    16.66  0.26538   0.88696  334          \r",
        "\r\n",
        "27 0    33.33  0.7673    3.3673   439          \r",
        "\r\n",
        "28 0    9.09   0.12484   0.53858  431          \r",
        "\r\n",
        "29 0    14.28  0.098915  0.59333  600          \r",
        "\r\n",
        "30 0    5.88   0.10285   0.45668  444          \r",
        "\r\n",
        "31 0    12.5   0.064753  0.40339  623          \r",
        "\r\n",
        "32 0    4.76   0.047048  0.32856  698          \r",
        "\r\n",
        "33 0    18.18  0.097229  0.55591  572          \r",
        "\r\n",
        "34 0    4.76   0.047835  0.32945  689          \r",
        "\r\n",
        "35 0    20     0.10541   0.53226  505          \r",
        "\r\n",
        "36 0    7.69   0.097477  0.40262  413          \r",
        "\r\n",
        "37 0    6.89   0.13695   0.42345  309          \r",
        "\r\n",
        "38 0    8.33   0.013201  0.22065  1670         \r",
        "\r\n",
        "39 0    11.11  0.078629  0.43467  553          \r",
        "\r\n",
        "40 0    4.76   0.064834  0.34992  540          \r",
        "\r\n",
        "41 0    7.14   0.043667  0.3612   827          \r",
        "\r\n",
        "42 0    14.28  0.13234   0.76682  579          \r",
        "\r\n",
        "43 0    3.57   0.046099  0.22381  486          \r",
        "\r\n",
        "44 0    20     0.079196  0.62198  785          \r",
        "\r\n",
        "45 0    21.42  0.30122   1.0117   336          \r",
        "\r\n",
        "46 0    22.05  0.17982   0.91112  507          \r",
        "\r\n",
        "47 0    2.17   0.0054445 0.076274 1400         \r",
        "\r\n",
        "48 0    10     0.031869  0.28573  897          \r",
        "\r\n",
        "49 0    4.385  0.038575  0.24347  631          \r",
        "\r\n",
        "50 0    9.752  0.13903   0.27036  194          \r",
        "\r\n",
        "51 0    4.081  0.016976  0.10939  644          \r",
        "\r\n",
        "52 0    32.478 0.26907   0.81567  303          \r",
        "\r\n",
        "53 0    6.003  0.075811  0.24588  324          \r",
        "\r\n",
        "54 0    19.829 0.044238  0.42934  971          \r",
        "\r\n",
        "55 1    1102.5 5.1915    31.729   611          \r",
        "\r\n",
        "56 1    9989   52.173    194.89   374          \r",
        "\r\n",
        "57 1    15841  283.29    606.35   214          \r",
        "\r\n",
        "58 0    1      0.39404   0.4887   124          \r",
        "\r\n",
        "\r",
        "\r\n",
        "\r",
        "\r\n",
        "This file: 'spambase.DOCUMENTATION' at the UCI Machine Learning Repository\r",
        "\r\n",
        "http://www.ics.uci.edu/~mlearn/MLRepository.html\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 236
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat spambase.names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 48 continuous real [0,100] attributes of type word_freq_WORD \r",
        "\r\n",
        "| = percentage of words in the e-mail that match WORD,\r",
        "\r\n",
        "| i.e. 100 * (number of times the WORD appears in the e-mail) / \r",
        "\r\n",
        "| total number of words in e-mail.  A \"word\" in this case is any \r",
        "\r\n",
        "| string of alphanumeric characters bounded by non-alphanumeric \r",
        "\r\n",
        "| characters or end-of-string.\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 6 continuous real [0,100] attributes of type char_freq_CHAR\r",
        "\r\n",
        "| = percentage of characters in the e-mail that match CHAR,\r",
        "\r\n",
        "| i.e. 100 * (number of CHAR occurences) / total characters in e-mail\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 1 continuous real [1,...] attribute of type capital_run_length_average\r",
        "\r\n",
        "| = average length of uninterrupted sequences of capital letters\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 1 continuous integer [1,...] attribute of type capital_run_length_longest\r",
        "\r\n",
        "| = length of longest uninterrupted sequence of capital letters\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 1 continuous integer [1,...] attribute of type capital_run_length_total\r",
        "\r\n",
        "| = sum of length of uninterrupted sequences of capital letters\r",
        "\r\n",
        "| = total number of capital letters in the e-mail\r",
        "\r\n",
        "|\r",
        "\r\n",
        "| 1 nominal {0,1} class attribute of type spam\r",
        "\r\n",
        "| = denotes whether the e-mail was considered spam (1) or not (0), \r",
        "\r\n",
        "| i.e. unsolicited commercial e-mail.  \r",
        "\r\n",
        "|\r",
        "\r\n",
        "| For more information, see file 'spambase.DOCUMENTATION' at the\r",
        "\r\n",
        "| UCI Machine Learning Repository: http://www.ics.uci.edu/~mlearn/MLRepository.html\r",
        "\r\n",
        "\r",
        "\r\n",
        "\r",
        "\r\n",
        "1, 0.    | spam, non-spam classes\r",
        "\r\n",
        "\r",
        "\r\n",
        "word_freq_make:         continuous.\r",
        "\r\n",
        "word_freq_address:      continuous.\r",
        "\r\n",
        "word_freq_all:          continuous.\r",
        "\r\n",
        "word_freq_3d:           continuous.\r",
        "\r\n",
        "word_freq_our:          continuous.\r",
        "\r\n",
        "word_freq_over:         continuous.\r",
        "\r\n",
        "word_freq_remove:       continuous.\r",
        "\r\n",
        "word_freq_internet:     continuous.\r",
        "\r\n",
        "word_freq_order:        continuous.\r",
        "\r\n",
        "word_freq_mail:         continuous.\r",
        "\r\n",
        "word_freq_receive:      continuous.\r",
        "\r\n",
        "word_freq_will:         continuous.\r",
        "\r\n",
        "word_freq_people:       continuous.\r",
        "\r\n",
        "word_freq_report:       continuous.\r",
        "\r\n",
        "word_freq_addresses:    continuous.\r",
        "\r\n",
        "word_freq_free:         continuous.\r",
        "\r\n",
        "word_freq_business:     continuous.\r",
        "\r\n",
        "word_freq_email:        continuous.\r",
        "\r\n",
        "word_freq_you:          continuous.\r",
        "\r\n",
        "word_freq_credit:       continuous.\r",
        "\r\n",
        "word_freq_your:         continuous.\r",
        "\r\n",
        "word_freq_font:         continuous.\r",
        "\r\n",
        "word_freq_000:          continuous.\r",
        "\r\n",
        "word_freq_money:        continuous.\r",
        "\r\n",
        "word_freq_hp:           continuous.\r",
        "\r\n",
        "word_freq_hpl:          continuous.\r",
        "\r\n",
        "word_freq_george:       continuous.\r",
        "\r\n",
        "word_freq_650:          continuous.\r",
        "\r\n",
        "word_freq_lab:          continuous.\r",
        "\r\n",
        "word_freq_labs:         continuous.\r",
        "\r\n",
        "word_freq_telnet:       continuous.\r",
        "\r\n",
        "word_freq_857:          continuous.\r",
        "\r\n",
        "word_freq_data:         continuous.\r",
        "\r\n",
        "word_freq_415:          continuous.\r",
        "\r\n",
        "word_freq_85:           continuous.\r",
        "\r\n",
        "word_freq_technology:   continuous.\r",
        "\r\n",
        "word_freq_1999:         continuous.\r",
        "\r\n",
        "word_freq_parts:        continuous.\r",
        "\r\n",
        "word_freq_pm:           continuous.\r",
        "\r\n",
        "word_freq_direct:       continuous.\r",
        "\r\n",
        "word_freq_cs:           continuous.\r",
        "\r\n",
        "word_freq_meeting:      continuous.\r",
        "\r\n",
        "word_freq_original:     continuous.\r",
        "\r\n",
        "word_freq_project:      continuous.\r",
        "\r\n",
        "word_freq_re:           continuous.\r",
        "\r\n",
        "word_freq_edu:          continuous.\r",
        "\r\n",
        "word_freq_table:        continuous.\r",
        "\r\n",
        "word_freq_conference:   continuous.\r",
        "\r\n",
        "char_freq_;:            continuous.\r",
        "\r\n",
        "char_freq_(:            continuous.\r",
        "\r\n",
        "char_freq_[:            continuous.\r",
        "\r\n",
        "char_freq_!:            continuous.\r",
        "\r\n",
        "char_freq_$:            continuous.\r",
        "\r\n",
        "char_freq_#:            continuous.\r",
        "\r\n",
        "capital_run_length_average: continuous.\r",
        "\r\n",
        "capital_run_length_longest: continuous.\r",
        "\r\n",
        "capital_run_length_total:   continuous.\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 237
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 238
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 239
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gotta get those headers, and I'll be damned if I'm going to copy and paste them all. I mean, I *could* train the filter on it without names, but how is that readable?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>0</th>\n",
        "      <th>1</th>\n",
        "      <th>2</th>\n",
        "      <th>3</th>\n",
        "      <th>4</th>\n",
        "      <th>5</th>\n",
        "      <th>6</th>\n",
        "      <th>7</th>\n",
        "      <th>8</th>\n",
        "      <th>9</th>\n",
        "      <th>...</th>\n",
        "      <th>48</th>\n",
        "      <th>49</th>\n",
        "      <th>50</th>\n",
        "      <th>51</th>\n",
        "      <th>52</th>\n",
        "      <th>53</th>\n",
        "      <th>54</th>\n",
        "      <th>55</th>\n",
        "      <th>56</th>\n",
        "      <th>57</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.32</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.778</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.756</td>\n",
        "      <td>  61</td>\n",
        "      <td>  278</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.28</td>\n",
        "      <td> 0.50</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.14</td>\n",
        "      <td> 0.28</td>\n",
        "      <td> 0.21</td>\n",
        "      <td> 0.07</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.94</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.132</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.372</td>\n",
        "      <td> 0.180</td>\n",
        "      <td> 0.048</td>\n",
        "      <td> 5.114</td>\n",
        "      <td> 101</td>\n",
        "      <td> 1028</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 0.06</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.71</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1.23</td>\n",
        "      <td> 0.19</td>\n",
        "      <td> 0.19</td>\n",
        "      <td> 0.12</td>\n",
        "      <td> 0.64</td>\n",
        "      <td> 0.25</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.01</td>\n",
        "      <td> 0.143</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.276</td>\n",
        "      <td> 0.184</td>\n",
        "      <td> 0.010</td>\n",
        "      <td> 9.821</td>\n",
        "      <td> 485</td>\n",
        "      <td> 2259</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.137</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.137</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.537</td>\n",
        "      <td>  40</td>\n",
        "      <td>  191</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td> 0.31</td>\n",
        "      <td> 0.63</td>\n",
        "      <td>...</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.135</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.135</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 3.537</td>\n",
        "      <td>  40</td>\n",
        "      <td>  191</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 58 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 240,
       "text": [
        "     0     1     2   3     4     5     6     7     8     9  ...    48     49  \\\n",
        "0  0.00  0.64  0.64   0  0.32  0.00  0.00  0.00  0.00  0.00 ...  0.00  0.000   \n",
        "1  0.21  0.28  0.50   0  0.14  0.28  0.21  0.07  0.00  0.94 ...  0.00  0.132   \n",
        "2  0.06  0.00  0.71   0  1.23  0.19  0.19  0.12  0.64  0.25 ...  0.01  0.143   \n",
        "3  0.00  0.00  0.00   0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.137   \n",
        "4  0.00  0.00  0.00   0  0.63  0.00  0.31  0.63  0.31  0.63 ...  0.00  0.135   \n",
        "\n",
        "   50     51     52     53     54   55    56  57  \n",
        "0   0  0.778  0.000  0.000  3.756   61   278   1  \n",
        "1   0  0.372  0.180  0.048  5.114  101  1028   1  \n",
        "2   0  0.276  0.184  0.010  9.821  485  2259   1  \n",
        "3   0  0.137  0.000  0.000  3.537   40   191   1  \n",
        "4   0  0.135  0.000  0.000  3.537   40   191   1  \n",
        "\n",
        "[5 rows x 58 columns]"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names = open(\"spambase.names\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "names.readline()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "'| SPAM E-MAIL DATABASE ATTRIBUTES (in .names format)\\n'"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "column_names = re.compile(r\"(^\\w+.):\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "name_text = names.readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns = []\n",
      "for line in name_text:\n",
      "    if column_names.match(line):\n",
      "        columns.append(column_names.match(line).groups(0)[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "given_match_object = columns[10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "given_match_object"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 247,
       "text": [
        "'word_freq_receive'"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 248,
       "text": [
        "['word_freq_make',\n",
        " 'word_freq_address',\n",
        " 'word_freq_all',\n",
        " 'word_freq_3d',\n",
        " 'word_freq_our',\n",
        " 'word_freq_over',\n",
        " 'word_freq_remove',\n",
        " 'word_freq_internet',\n",
        " 'word_freq_order',\n",
        " 'word_freq_mail',\n",
        " 'word_freq_receive',\n",
        " 'word_freq_will',\n",
        " 'word_freq_people',\n",
        " 'word_freq_report',\n",
        " 'word_freq_addresses',\n",
        " 'word_freq_free',\n",
        " 'word_freq_business',\n",
        " 'word_freq_email',\n",
        " 'word_freq_you',\n",
        " 'word_freq_credit',\n",
        " 'word_freq_your',\n",
        " 'word_freq_font',\n",
        " 'word_freq_000',\n",
        " 'word_freq_money',\n",
        " 'word_freq_hp',\n",
        " 'word_freq_hpl',\n",
        " 'word_freq_george',\n",
        " 'word_freq_650',\n",
        " 'word_freq_lab',\n",
        " 'word_freq_labs',\n",
        " 'word_freq_telnet',\n",
        " 'word_freq_857',\n",
        " 'word_freq_data',\n",
        " 'word_freq_415',\n",
        " 'word_freq_85',\n",
        " 'word_freq_technology',\n",
        " 'word_freq_1999',\n",
        " 'word_freq_parts',\n",
        " 'word_freq_pm',\n",
        " 'word_freq_direct',\n",
        " 'word_freq_cs',\n",
        " 'word_freq_meeting',\n",
        " 'word_freq_original',\n",
        " 'word_freq_project',\n",
        " 'word_freq_re',\n",
        " 'word_freq_edu',\n",
        " 'word_freq_table',\n",
        " 'word_freq_conference',\n",
        " 'char_freq_;',\n",
        " 'char_freq_(',\n",
        " 'char_freq_[',\n",
        " 'char_freq_!',\n",
        " 'char_freq_$',\n",
        " 'char_freq_#',\n",
        " 'capital_run_length_average',\n",
        " 'capital_run_length_longest',\n",
        " 'capital_run_length_total']"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Oh, yeah. We're cooking with oil now."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With gas? What's that saying? Huh..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(columns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "57"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data[57]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 250,
       "text": [
        "0     1\n",
        "1     1\n",
        "2     1\n",
        "3     1\n",
        "4     1\n",
        "5     1\n",
        "6     1\n",
        "7     1\n",
        "8     1\n",
        "9     1\n",
        "10    1\n",
        "11    1\n",
        "12    1\n",
        "13    1\n",
        "14    1\n",
        "...\n",
        "4586    0\n",
        "4587    0\n",
        "4588    0\n",
        "4589    0\n",
        "4590    0\n",
        "4591    0\n",
        "4592    0\n",
        "4593    0\n",
        "4594    0\n",
        "4595    0\n",
        "4596    0\n",
        "4597    0\n",
        "4598    0\n",
        "4599    0\n",
        "4600    0\n",
        "Name: 57, Length: 4601, dtype: int64"
       ]
      }
     ],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "columns.append(\"is_spam\")\n",
      "spam_data.columns = columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 251
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spam_data_np = spam_data.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 253
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training, testing = train_test_split(spam_data_np, test_size=0.4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 254
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 255,
       "text": [
        "(2760, 58)"
       ]
      }
     ],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_dep = training[:,:-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_dep.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 257,
       "text": [
        "(2760, 57)"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_target = training[:, -1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training_target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 259,
       "text": [
        "(2760, 1)"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#training_target = training_target.reshape(1, -1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 260
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#training_target.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#training_dep = training_dep.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bayes_filter = GaussianNB()\n",
      "bayes_filter.fit(training_dep, training_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/naive_bayes.py:150: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
        "  y = column_or_1d(y, warn=True)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "GaussianNB()"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions = bayes_filter.predict(testing[:,:-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "def test_display_prediction(correct, predictions):\n",
      "    print(metrics.classification_report(correct, predictions))\n",
      "    print(metrics.confusion_matrix(correct, predictions))\n",
      "    print(metrics.f1_score(correct, predictions))\n",
      "test_display_prediction(testing_target, predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.97      0.72      0.82      1096\n",
        "        1.0       0.70      0.96      0.81       745\n",
        "\n",
        "avg / total       0.86      0.82      0.82      1841\n",
        "\n",
        "[[788 308]\n",
        " [ 27 718]]\n",
        "0.81084133258\n"
       ]
      }
     ],
     "prompt_number": 295
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Perceptron\n",
      "perceptron_classifier = Perceptron()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perceptron_classifier.fit(training_dep, training_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/linear_model/stochastic_gradient.py:321: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
        "  y = column_or_1d(y, warn=True)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 268,
       "text": [
        "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
        "      n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=False,\n",
        "      verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testing_dep = testing[:, :-1]\n",
      "testing_target = testing[:, -1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "perceptron_predict = perceptron_classifier.predict(testing_dep)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_display_prediction(testing_target, perceptron_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       1.00      0.06      0.11      1096\n",
        "        1.0       0.42      1.00      0.59       745\n",
        "\n",
        "avg / total       0.76      0.44      0.30      1841\n",
        "\n",
        "[[  61 1035]\n",
        " [   0  745]]\n",
        "0.590099009901\n"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 272
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linear_classifier = LinearRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 273
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linear_classifier.fit(training_dep, training_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 274,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 274
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "linear_prediction = linear_classifier.predict(testing_dep)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_display_prediction(testing_target, linear_prediction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Mix type of y not allowed, got types {'continuous', 'binary'}",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-276-175e99d54f98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_display_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_prediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-266-9b75b1353936>\u001b[0m in \u001b[0;36mtest_display_prediction\u001b[0;34m(correct, predictions)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_display_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/metrics/metrics.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_types\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix type of y not allowed, got types %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mys_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mlabel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mys_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: Mix type of y not allowed, got types {'continuous', 'binary'}"
       ]
      }
     ],
     "prompt_number": 276
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, actually, we want to use a logit regression. I very dimly recall this from my days getting a C- in an econometrics class. Logistic regressions are particularly well-adapted to cases where we're trying to predict a binary outcome."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 277
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_classifier = LogisticRegression()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 278
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_classifier.fit(training_dep, training_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/preprocessing/label.py:125: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
        "  y = column_or_1d(y, warn=True)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 279,
       "text": [
        "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 279
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logit_predictions = logit_classifier.predict(testing_dep)\n",
      "logit_predictions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 281,
       "text": [
        "array([ 1.,  0.,  1., ...,  0.,  0.,  1.])"
       ]
      }
     ],
     "prompt_number": 281
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_display_prediction(testing_target, logit_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.93      0.95      0.94      1096\n",
        "        1.0       0.93      0.89      0.91       745\n",
        "\n",
        "avg / total       0.93      0.93      0.93      1841\n",
        "\n",
        "[[1043   53]\n",
        " [  83  662]]\n",
        "0.906849315068\n"
       ]
      }
     ],
     "prompt_number": 282
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wow, that actually worked fairly well. Let's try to use a different Bayes classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multi_bayes = MultinomialNB()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multi_bayes.fit(training_dep, training_target)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/gordon/.pyenv/versions/sandbox/lib/python3.4/site-packages/sklearn/naive_bayes.py:301: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
        "  y = column_or_1d(y, warn=True)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 285,
       "text": [
        "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
       ]
      }
     ],
     "prompt_number": 285
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "multi_bayes_predictions = multi_bayes.predict(testing_dep)\n",
      "multi_bayes_predictions.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 292,
       "text": [
        "(1841,)"
       ]
      }
     ],
     "prompt_number": 292
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_display_prediction(testing_target, multi_bayes_predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        0.0       0.80      0.82      0.81      1096\n",
        "        1.0       0.73      0.70      0.71       745\n",
        "\n",
        "avg / total       0.77      0.77      0.77      1841\n",
        "\n",
        "[[899 197]\n",
        " [224 521]]\n",
        "0.712235133288\n"
       ]
      }
     ],
     "prompt_number": 294
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, for a Gaussian Naive Bayes, we got a score of about 0.80, for a Logit Regression we got a score of about 0.90, and for a Multinomial Naive Bayes, we got a score of about 0.70. Good job, Logit Regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}